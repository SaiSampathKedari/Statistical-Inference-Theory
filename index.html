<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="IWjrJMnvlawH7rGbfjRi0pACtdTmTmeDLeyyDcO9-bc">

  <title>Statistical Inference Theory | Casella-Berger | UMich STATS 511 | MIT 18.650</title>
  <meta name="description" content="Lecture notes and solved exercises from Casella-Berger Statistical Inference, MIT 18.650, and UMich STATS 511 â€” covering estimation, testing, and intervals for machine learning, AI, and robotics.">
  <meta name="author" content="Sai Sampath Kedari">
  <meta property="og:title" content="Statistical Inference Theory - Casella-Berger - UMich STATS 511 - MIT 18.650">
  <meta property="og:description" content="Lecture notes, problem sets, and inference foundations for ML, AI, and Robotics.">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://saisampathkedari.github.io/Statistical-Inference-Theory/">
  <meta name="twitter:card" content="summary">

  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Inter, Ubuntu, sans-serif;
           line-height: 1.6; margin: 0; padding: 0; background: #0b0f17; color: #e5e7eb; }
    .container { max-width: 900px; margin: auto; padding: 40px 20px; }
    h1 { font-size: 2.1rem; margin-bottom: 0.2em; }
    h2 { color: #93c5fd; margin-top: 1.5em; }
    a { color: #60a5fa; text-decoration: none; }
    a:hover { text-decoration: underline; }
    code { background: #111827; padding: 2px 6px; border-radius: 6px; }
    ul { margin-left: 1.2em; }
    footer { margin-top: 40px; border-top: 1px solid #1f2937; padding-top: 20px; color: #9ca3af; font-size: 0.9em; }
  </style>
</head>
<body>
  <div class="container">
    <h1>Statistical Inference Theory â€” Casella-Berger | UMich STATS 511 | MIT 18.650</h1>
    <p>This repository contains my <strong>lecture notes</strong> and <strong>solved exercises</strong> from <em>Casella & Berger: Statistical Inference (Chapters 6â€“9)</em>, along with supporting materials from <strong>MIT 18.650</strong> and <strong>UMich STATS 511</strong>. The focus is on <strong>point estimation, hypothesis testing, and interval estimation</strong> â€” the core pillars of modern <strong>Machine Learning, AI, and Robotics</strong>.</p>

    <h2>Key Topics Covered</h2>
    <ol>
      <li><strong>Principles of Data Reduction</strong>: Sufficiency, Minimal Sufficiency, Ancillary Statistics, Complete Statistics, and the Likelihood Principle.</li>
      <li><strong>Point Estimation</strong>: Methods of Moments, Maximum Likelihood, Bayes Estimators, EM Algorithm, Evaluating Estimators, and Fisher Information.</li>
      <li><strong>Hypothesis Testing</strong>: Neyman-Pearson Lemma, Likelihood Ratio Tests, and Decision Theory.</li>
      <li><strong>Interval Estimation</strong>: Confidence Intervals, Bayesian Credible Intervals, and Large Sample Approximations.</li>
    </ol>

    <h2>Repository Structure</h2>
    <ul>
      <li><strong>Lecture Notes</strong>: Summaries of theoretical concepts with detailed derivations.</li>
      <li><strong>Problem Sets</strong>: Solved exercises from <em>Casella-Berger</em> to reinforce concepts.</li>
      <li><strong>Supplementary Resources</strong>: Insights from <strong>UMich STATS 511</strong> and <strong>MIT 18.650</strong>.</li>
    </ul>

    <h2>Purpose</h2>
    <p>This work builds a <strong>rigorous foundation in Statistical Inference</strong> essential for <strong>Statistical Machine Learning, Computational Statistics, and Probabilistic Robotics</strong>. These concepts form the backbone of <strong>Monte Carlo Methods, Bayesian Filtering, and State Estimation</strong> â€” critical for modern control systems and AI-driven robots.</p>

    <p>By mastering these principles, I aim to unify <strong>theory and implementation</strong> in <strong>robotics and autonomous systems</strong>, developing probabilistic models and decision algorithms grounded in mathematical clarity.</p>

    <h2>About Me</h2>
    <p>Iâ€™m focused on building deep <strong>mathematical and statistical foundations</strong> for <strong>Robotics, AI, and State Estimation</strong>.</p>

    <p><strong>Contact:</strong><br>
      ðŸ“§ <a href="mailto:sampath@umich.edu">sampath@umich.edu</a><br>
      ðŸ”— <a href="https://www.linkedin.com/in/sai-sampath-kedari" target="_blank">LinkedIn Profile</a><br>
      ðŸ§  <a href="https://github.com/SaiSampathKedari/Statistical-Inference-Theory" target="_blank">View GitHub Repository</a>
    </p>

    <footer>
      <p>Â© <span id="year"></span> Sai Sampath Kedari â€” Casella-Berger, MIT 18.650, UMich STATS 511 | Built for visibility, clarity, and rigorous math.</p>
    </footer>
  </div>

  <script>document.getElementById("year").textContent = new Date().getFullYear();</script>
</body>
</html>
